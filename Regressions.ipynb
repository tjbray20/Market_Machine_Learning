{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Regresssions\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table of Contents:\n",
    "- [Library Imports](#Library-Imports)\n",
    "- [Preprocessing the Data](#Preprocessing-the-Data)\n",
    "- [Models](#Models)\n",
    "    - [Elastic Net](#Elastic-Net)\n",
    "    - [Support Vector Regression](#Support-Vector-Regression)\n",
    "    - [Ridge](#Ridge)\n",
    "- [Looping Through the Data](#Looping-Through-the-Data)\n",
    "- [Residual Plots](#Residual-Plots)\n",
    "- [Results](#Results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Imports\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import LinearSVR\n",
    "from statsmodels.regression.rolling import RollingOLS\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the Data\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function removes highly correlated variables within the dataset. The function looks at the \n",
    "# Pearson Correlation Coefficient between every pair of variables in the dataset and returns all \n",
    "# of those between .8 and .999. While working with data from different companies, I found that by\n",
    "# removing the first 90% of correlated variables within the DataFrame, in almost all cases, there\n",
    "# were no longer correlations within the dataset.\n",
    "\n",
    "def remove_corrs(df):\n",
    "    \n",
    "    # create a DataFrame with all the of the correlation coefficients, and then stack the pairings.\n",
    "    corrs = df.corr().stack().reset_index()\n",
    "    corrs.columns = ['1','2','R2']\n",
    "    # create a temoporary DataFrame that contains all the pairs of variables that have a correlation\n",
    "    # between .8 and .999. Because the .corr() method returns the pairings in both directions, I only\n",
    "    # look at half of the cells because of duplicates.\n",
    "    temp = corrs[(corrs.R2 > .8) & (corrs.R2 < .999)].sort_values('R2', ascending = False).reset_index(drop = True)\n",
    "    correlations = temp[temp.index % 2 == 0]\n",
    "    \n",
    "    # look at how many times each variable shows up in the correlation column\n",
    "    corr_index = correlations['1'].value_counts().index\n",
    "    # delete the first 90% of the variables. This generally removes the columns that are most correlated with the others. \n",
    "    to_drop = round(len(corr_index)*.9)\n",
    "    \n",
    "    df2 = df.drop(corr_index[:to_drop], axis = 1)\n",
    "    \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function preprocesses my data so it is ready for distanced based regressions.\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    \n",
    "    # Here, I shift all the independent variables back one day in order to make sure there is\n",
    "    # no data leakage. Because we're trying to predict closing price, we can't know many of\n",
    "    # things that happen throughout the day we're trying to predict.\n",
    "    X = df.shift(1).dropna()\n",
    "    \n",
    "    # This is the function described above.\n",
    "    X_data = remove_corrs(X)\n",
    "\n",
    "    # Because I am running a regression, I can use a continuous variable as my dependent variable.\n",
    "    # Ideally, my algorithim can predict the closing price at the end of the day with accuracy.\n",
    "    y = df['adjustedclose'].iloc[1:]\n",
    "    \n",
    "    # Do a train test split with the first 80% of the data being the training set and the last 20%\n",
    "    # as the testing set.\n",
    "    train_num = round(len(X)*.8)\n",
    "    test_num = round(len(X)*.2)\n",
    "    print(train_num, test_num)\n",
    "\n",
    "    X_train = X_data.iloc[:train_num]\n",
    "    X_test = X_data.iloc[-test_num:]\n",
    "    y_train = y.iloc[:train_num]\n",
    "    y_test = y.iloc[-test_num:]\n",
    "    \n",
    "    # Because I am doing distance based regressions, I need to scale the data so that variables with\n",
    "    # higher absolute values don't dominate the metrics.\n",
    "    ss = StandardScaler()\n",
    "    X_train_scaled = ss.fit_transform(X_train)\n",
    "    X_test_scaled = ss.transform(X_test)\n",
    "\n",
    "    X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns).set_index(X_train.index)\n",
    "    X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns).set_index(X_test.index)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EN_test(X_train, X_test, y_train, y_test, cv=5):\n",
    "    \n",
    "    # Set GridSearchCV hyperparameters to compare & select\n",
    "    grid = {\n",
    "    'l1_ratio': [.01,.25,.5,.75,1],\n",
    "    'alpha': [.01,.25,.5,.75,1],\n",
    "    }\n",
    "    \n",
    "    # Instantiate & fit RidgeRegression\n",
    "    en = ElasticNet(random_state = 42, max_iter = 10e5)\n",
    "    \n",
    "    # Instantiate & fit GridSearchCV with accuracy scoring\n",
    "    gs = GridSearchCV(estimator=en, param_grid=grid, cv=cv, scoring='neg_root_mean_squared_error', n_jobs = -1)\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    # Create prediction variable using test data\n",
    "    y_hat_train = gs.predict(X_train)\n",
    "    y_hat_test = gs.predict(X_test)\n",
    "    \n",
    "    # Run cross-validate score with cv folds from function parameter\n",
    "    cv_results = cross_val_score(gs, X_train, y_train, cv=cv, scoring = 'neg_root_mean_squared_error')\n",
    "\n",
    "    # Score the train and test sets.\n",
    "    train_score = gs.score(X_train, y_train)\n",
    "    test_score = gs.score(X_test, y_test)\n",
    "    \n",
    "    print(f'Train RMSE: {train_score}')\n",
    "    print(f'Mean Cross-Val Score: {cv_results.mean()}')\n",
    "    print(f'Test RMSE: {test_score}')\n",
    "\n",
    "    # Create a DataFrame that has the predictions for the given days of the train set.\n",
    "    preds_train = pd.concat([y_train, pd.DataFrame(y_hat_train, columns = ['predictions'], index = y_train.index), df.day_direction], axis = 1)\n",
    "    preds_train.dropna(inplace = True)\n",
    "\n",
    "    # Compare the direction of the predicted value with what actually happened on the given day.\n",
    "    preds_train['direction'] = np.where(preds_train.predictions > preds_train.adjustedclose.shift(1), 1, 0)\n",
    "    preds_train['correct'] = np.where(preds_train['direction'] == preds_train['day_direction'], 1, 0)\n",
    "    train_accuracy = preds_train['correct'].value_counts(normalize = True)\n",
    "    \n",
    "    # Create a DataFrame that has the predictions for the given days of the test set.\n",
    "    preds_test = pd.concat([y_test, pd.DataFrame(y_hat_test, columns = ['predictions'], index = y_test.index), df.day_direction], axis = 1)\n",
    "    preds_test.dropna(inplace = True)\n",
    "\n",
    "    # Compare the direction of the predicted value with what actually happend on the given day. \n",
    "    preds_test['direction'] = np.where(preds_test.predictions > preds_test.adjustedclose.shift(1), 1, 0)\n",
    "    preds_test['correct'] = np.where(preds_test['direction'] == preds_test['day_direction'], 1, 0)\n",
    "    test_accuracy = preds_test['correct'].value_counts(normalize = True)\n",
    "\n",
    "    print(f'Train accuracy: {train_accuracy[1]}')\n",
    "    print(f'Test accuracy: {test_accuracy[1]}')\n",
    "    \n",
    "    # Return the results in a list that can later be appended to a DataFrame.\n",
    "    results = ['elastic net', train_score, cv_results.mean(), test_score, train_accuracy[1], test_accuracy[1]]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVR_test(X_train, X_test, y_train, y_test, cv=5):\n",
    "    \n",
    "    svr = LinearSVR(random_state = 42, max_iter = 10e5)\n",
    "    svrmodel = svr.fit(X_train, y_train)\n",
    "    \n",
    "    train_score = svr.score(X_train, y_train)\n",
    "    y_hat_train = svr.predict(X_train)\n",
    "    train_rmse = mean_squared_error(y_train, y_hat_train, squared = False)\n",
    "    train_cv_score = cross_val_score(svrmodel, X_train, y_train, scoring = 'neg_root_mean_squared_error').mean()\n",
    "    \n",
    "    test_score = svr.score(X_test, y_test)\n",
    "    y_hat_test = svr.predict(X_test)\n",
    "    test_rmse = mean_squared_error(y_test, y_hat_test, squared = False)\n",
    "    \n",
    "    preds_train = pd.concat([y_train, pd.DataFrame(y_hat_train, columns = ['predictions'], index = y_train.index), df.day_direction], axis = 1)\n",
    "    preds_train.dropna(inplace = True)\n",
    "\n",
    "    preds_train['direction'] = np.where(preds_train.predictions > preds_train.adjustedclose.shift(1), 1, 0)\n",
    "    preds_train['correct'] = np.where(preds_train['direction'] == preds_train['day_direction'], 1, 0)\n",
    "    train_accuracy = preds_train['correct'].value_counts(normalize = True)\n",
    "    \n",
    "    preds_test = pd.concat([y_test, pd.DataFrame(y_hat_test, columns = ['predictions'], index = y_test.index), df.day_direction], axis = 1)\n",
    "    preds_test.dropna(inplace = True)\n",
    "\n",
    "    preds_test['direction'] = np.where(preds_test.predictions > preds_test.adjustedclose.shift(1), 1, 0)\n",
    "    preds_test['correct'] = np.where(preds_test['direction'] == preds_test['day_direction'], 1, 0)\n",
    "    test_accuracy = preds_test['correct'].value_counts(normalize = True)\n",
    "    \n",
    "    print(f'Train RMSE : {train_rmse}')\n",
    "    print(f'Mean Train Cross-Validation RMSE: {train_cv_score}')\n",
    "    print(f'Test RMSE : {test_rmse}')\n",
    "    print(f'Train accuracy: {train_accuracy[1]}')\n",
    "    print(f'Test accuracy: {test_accuracy[1]}')\n",
    " \n",
    "    results = ['SVR', train_score, train_cv_score, test_score, train_accuracy[1], test_accuracy[1]]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ridge_test(X_train, X_test, y_train, y_test, cv=5):\n",
    "    \n",
    "    # Set GridSearchCV hyperparameters to compare & select\n",
    "    grid = {\n",
    "    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga', 'lbfgs'],\n",
    "    'alpha': [.01, .05, .1,.5,.75,1],\n",
    "    }\n",
    "    \n",
    "    # Instantiate & fit RidgeRegression\n",
    "    ridge = Ridge(random_state = 42, max_iter = 10e5)\n",
    "    \n",
    "    # Instantiate & fit GridSearchCV with accuracy scoring\n",
    "    gs = GridSearchCV(estimator=ridge, param_grid=grid, cv=cv, scoring='r2', n_jobs = -1)\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    # Return best hyperparameters\n",
    "    ridge_params = gs.best_params_\n",
    "    \n",
    "    # Create prediction variable using test data\n",
    "    y_hat_train = gs.predict(X_train)\n",
    "    y_hat_test = gs.predict(X_test)\n",
    "\n",
    "    # Run cross-validate score with cv folds from function parameter\n",
    "    train_cv_score = cross_val_score(gs, X_train, y_train, cv=cv, scoring = 'neg_root_mean_squared_error').mean()\n",
    "    \n",
    "    # Run and print accuracy, recall, precision and f1 scores\n",
    "    train_score = gs.score(X_train, y_train)\n",
    "    test_score = gs.score(X_test, y_test)\n",
    "\n",
    "    train_rmse = mean_squared_error(y_train, y_hat_train, squared = False)\n",
    "    test_rmse = mean_squared_error(y_test, y_hat_test, squared = False)\n",
    "    \n",
    "    preds_train = pd.concat([y_train, pd.DataFrame(y_hat_train, columns = ['predictions'], index = y_train.index), df.day_direction], axis = 1)\n",
    "    preds_train.dropna(inplace = True)\n",
    "\n",
    "    preds_train['direction'] = np.where(preds_train.predictions > preds_train.adjustedclose.shift(1), 1, 0)\n",
    "    preds_train['correct'] = np.where(preds_train['direction'] == preds_train['day_direction'], 1, 0)\n",
    "    train_accuracy = preds_train['correct'].value_counts(normalize = True)\n",
    "    \n",
    "    preds_test = pd.concat([y_test, pd.DataFrame(y_hat_test, columns = ['predictions'], index = y_test.index), df.day_direction], axis = 1)\n",
    "    preds_test.dropna(inplace = True)\n",
    "\n",
    "    preds_test['direction'] = np.where(preds_test.predictions > preds_test.adjustedclose.shift(1), 1, 0)\n",
    "    preds_test['correct'] = np.where(preds_test['direction'] == preds_test['day_direction'], 1, 0)\n",
    "    test_accuracy = preds_test['correct'].value_counts(normalize = True)\n",
    "    \n",
    "    print(f'Train RMSE : {train_rmse}')\n",
    "    print(f'Mean Train Cross-Validation RMSE: {train_cv_score}')\n",
    "    print(f'Test RMSE : {test_rmse}')\n",
    "    print(f'Train accuracy: {train_accuracy[1]}')\n",
    "    print(f'Test accuracy: {test_accuracy[1]}')\n",
    " \n",
    "    results = ['Ridge', train_rmse, train_cv_score, test_rmse, train_accuracy[1], test_accuracy[1]]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looping Through the Data\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the files in the Formatted Data folder.\n",
    "files = [f for f in listdir('.\\FormattedData')]\n",
    "\n",
    "# create a list of companies that can be analyzed.\n",
    "companies = []\n",
    "for i in files:\n",
    "    company = i.split('.')[0]\n",
    "    companies.append(company)\n",
    "\n",
    "# create a list of random companies to analyze from within the formatted companies\n",
    "test_companies = np.random.choice(companies, 1, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_companies = ['FE_formatted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1798 450\n",
      "Train RMSE: -0.7576826509571929\n",
      "Mean Cross-Val Score: -1.62700207745889\n",
      "Test RMSE: -8.367635203412112\n",
      "Train accuracy: 0.5261401557285873\n",
      "Test accuracy: 0.5644444444444444\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-3ae4a1ed9df9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0men_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEN_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0msvr_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVR_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mridge_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRidge_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     c_results = pd.DataFrame([en_results, svr_results, ridge_results],\n",
      "\u001b[1;32m<ipython-input-26-1d491a782f7c>\u001b[0m in \u001b[0;36mSVR_test\u001b[1;34m(X_train, X_test, y_train, y_test, cv)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0msvr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearSVR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10e5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0msvrmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtrain_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\learn-env\\lib\\site-packages\\sklearn\\svm\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    416\u001b[0m                                    accept_large_sparse=False)\n\u001b[0;32m    417\u001b[0m         \u001b[0mpenalty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'l2'\u001b[0m  \u001b[1;31m# SVR only accepts l2 penalty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 418\u001b[1;33m         self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n\u001b[0m\u001b[0;32m    419\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_scaling\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\learn-env\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     \u001b[0msolver_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_liblinear_solver_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdual\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 966\u001b[1;33m     raw_coef_, n_iter_ = liblinear.train_wrap(\n\u001b[0m\u001b[0;32m    967\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# loop through the companies and perform the different alogrithims. Create a\n",
    "# list of DataFrames that can then be used to compared results across different\n",
    "# companies and algorithms.\n",
    "\n",
    "results = []\n",
    "\n",
    "for c in test_companies:\n",
    "    csv_for_df = f'FormattedData/{c}.csv'\n",
    "    df = pd.read_csv(csv_for_df, index_col = 0)\n",
    "    X_train, X_test, y_train, y_test = preprocess_data(df)\n",
    "    en_results = EN_test(X_train, X_test, y_train, y_test)\n",
    "    svr_results = SVR_test(X_train, X_test, y_train, y_test)\n",
    "    ridge_results = Ridge_test(X_train, X_test, y_train, y_test)\n",
    "    c_results = pd.DataFrame([en_results, svr_results, ridge_results],\n",
    "            columns = ['Model Type', 'Train RMSE', 'Cross-Val RMSE', 'Test RMSE', \n",
    "             'Train Accuracy', 'Test Accuracy'])\n",
    "    c_results['company'] = c.split('_')[0]\n",
    "    results.append(c_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results\n",
    "tests = pd.concat(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (24,7))\n",
    "plot_x = y_train.index\n",
    "plot_y = (y_hat_train - y_train)/y_train\n",
    "plt.scatter(plot_x,plot_y)\n",
    "ax.yaxis.set_major_formatter('{x:1,.2%}')\n",
    "plt.axhline(y=0, alpha = .5, color = 'red', linewidth = 4.0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax = plt.subplots(figsize = (24,7))\n",
    "ax.scatter(y_test.index, (y_hat_test - y_test)/y_test)\n",
    "ax.yaxis.set_major_formatter('{x:1,.2%}')\n",
    "plt.axhline(y=0, alpha = 1, color = 'red');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3, ax = plt.subplots(figsize = (24,7))\n",
    "fig3_data = preds_test[(preds_test.index >= '1-1-2020') & (preds_test.index <= '4-1-2021')]\n",
    "ax.plot(fig3_data.adjustedclose, linewidth = 3.0)\n",
    "ax.plot(fig3_data.predictions)\n",
    "ax.yaxis.set_major_formatter('${x:1,.2f}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4, ax = plt.subplots(figsize = (24,7))\n",
    "fig4_data = preds_train[(preds_train.index >= '1-1-2018') & (preds_train.index <= '1-1-2020')]\n",
    "ax.plot(fig4_data.adjustedclose, linewidth = 3.0)\n",
    "ax.plot(fig4_data.predictions)\n",
    "ax.yaxis.set_major_formatter('${x:1,.2f}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
